{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><b><u>Credit Risk Modelling</u></b></center></h1>\n",
    "This Notebook make use of the findings of Credit_risk_assements_analysis notebook & develop a credit risk classification model.<br>\n",
    "Steps involved:-\n",
    "<ul>\n",
    "    <li>Data Preparation where we perform all the processing steps explained in analysis notebook</li>\n",
    "    <li>Splitting Data into train & test for modelling</li>\n",
    "    <li>Model Selection & Parameter tunning using gridSearchCV</li>\n",
    "    <li>Use the best estimator & train it on training dataset</li>\n",
    "    <li>Get the f1_score & Confusion Matrix on the test dataset</li>\n",
    "</ul>\n",
    "</br>\n",
    "<b>Note :- </b> \n",
    "<ul>\n",
    "    <li>Distribution of data between Default & No Default is <b>imbalanced</b> so to overcome that <b>class weight balancer technique</b> is used, where we assign weights to each class based on their ratios.</li>\n",
    "    <li>For performance Evaluation <b>f1_score</b> is being used as this scores consider both precision & recall for validating model. Based on business requirements this metric can be changed based on the crticality of Default / No Default classification</li>\n",
    "    <li>In this we transformed continuos variables into categoricla variables by creating ban0ds (Ex:- Cibil_score from 0-600 will be replaced by band_1 & so on) of different bins size. Identification of this bins is being done usinf Weight of Evidence method in analysis notebook</li>\n",
    "    <li> Advantage of converting continuos variables into bands helps us in handling outliers, as extreme outliers will be merged with the nearest valid values while creation of groups</li> \n",
    "    <li> Example for band :- [-1.0, 665.0, 705.0, 858.0] so in this values from -1 to 665 all comes in one group named as band_1, similarly for 666 to 705 will come in band_2 & so on</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\dask\\dataframe\\utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, plot_confusion_matrix, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 21\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><u><center>Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Loans data processing </h3>\n",
    "Selection of variables based on the outcome of Credit risk assessments analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_loans = pd.read_csv(\"data_loans_5k.csv\",parse_dates=[\"disbursed_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_column_selected = [\"master_user_id\",\n",
    "                         \"max_dpd\",\n",
    "                         \"is_non_starter\",\n",
    "                         \"amount\",\n",
    "                         \"disbursed_at\",\n",
    "                         \"period\"\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df = raw_loans[loans_column_selected].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df[\"target\"] = np.where(default_df[\"max_dpd\"] > 30, \"Default\", \"No Default\")\n",
    "default_df.drop(\"max_dpd\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Below section will create two columns in loans dataframe</h4>\n",
    "<ul>\n",
    "    <li><b>past_default_count :- </b> This columns stores the information that how many time user has defaulted in past before applying for this loan.</li>\n",
    "        <li><b>total_past_records :- </b> This columns stores the information about the user that for how many times he has applied for loans & get approved before this particular loan application disbursed.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_code = \"\"\"\n",
    "select A.*,\n",
    "    CASE\n",
    "        WHEN B.target = \"Default\" THEN 1\n",
    "        ELSE 0\n",
    "    END as past_default_count,\n",
    "    CASE\n",
    "        WHEN B.master_user_id is NOT NULL THEN 1\n",
    "        ELSE 0\n",
    "    END as total_past_records\n",
    "from default_df as A\n",
    "left join default_df as B\n",
    "on A.master_user_id = B.master_user_id\n",
    "and A.disbursed_at > B.disbursed_at\n",
    "\"\"\"\n",
    "intermediate_df = ps.sqldf(sql_code,locals())\n",
    "\n",
    "def aggregator(df):\n",
    "    result = df.iloc[0]\n",
    "    result[\"past_default_count\"] = sum(df.past_default_count)\n",
    "    result[\"total_past_records\"] = sum(df.total_past_records) + 1\n",
    "    return result\n",
    "\n",
    "processed_loan_df = intermediate_df.groupby([\"master_user_id\",\n",
    "                                             \"disbursed_at\"]).\\\n",
    "                                    apply(aggregator).\\\n",
    "                                    reset_index(drop=True)\n",
    "del(intermediate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master_user_id</th>\n",
       "      <th>is_non_starter</th>\n",
       "      <th>amount</th>\n",
       "      <th>disbursed_at</th>\n",
       "      <th>period</th>\n",
       "      <th>target</th>\n",
       "      <th>past_default_count</th>\n",
       "      <th>total_past_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2016-02-15 14:42:10.038000</td>\n",
       "      <td>3</td>\n",
       "      <td>No Default</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2016-06-27 00:00:00.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>No Default</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   master_user_id  is_non_starter   amount                disbursed_at  \\\n",
       "0               1               0  10000.0  2016-02-15 14:42:10.038000   \n",
       "1               1               0   9000.0  2016-06-27 00:00:00.000000   \n",
       "\n",
       "   period      target  past_default_count  total_past_records  \n",
       "0       3  No Default                   0                   1  \n",
       "1       3  No Default                   0                   2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_loan_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Assessments data processing </h3>\n",
    "Selection of variables based on the outcome of Credit risk assessments analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_assessments = pd.read_csv(\"data_assessments_5k.csv\", parse_dates=[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_column_selected = [\"master_user_id\",\n",
    "                              \"created_at\",\n",
    "                              \"reason_premium\",\n",
    "                              \"reason_flexi\",\n",
    "                              \"cibil_score\",\n",
    "                              \"stated_income\",\n",
    "                              \"line_amount\",\n",
    "                              \"product_type\"\n",
    "                             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_assessments = raw_assessments[assessment_column_selected].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(raw_assessments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Join both Loan data & Assessments data</h3>\n",
    "Join Condition: -\n",
    "<ul>\n",
    "    <li>master_user_id</li>\n",
    "    <li>loans.disbursed_at > assessment.created_at</li>\n",
    "    <li>Keep only the latest assessments which decided the loans approval decision</li>\n",
    "</ul>\n",
    "<b>Note: -</b> Reason behind removing all the assessments & keeping only the latest one is to get the assessment on which that loan is approved. as this is where we have to look what we can improve in our model to classify defaulters better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in processed_assessments.columns if col !=\"master_user_id\"]\n",
    "column_string = \"B.\" +\", B.\".join(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_join = f\"\"\"\n",
    "SELECT A.*,\n",
    "    {column_string}\n",
    "from processed_loan_df as A\n",
    "left join processed_assessments as B\n",
    "on A.master_user_id = B.master_user_id\n",
    "    and A.disbursed_at > B.created_at\n",
    "\"\"\"\n",
    "joined_intermediate_df = ps.sqldf(sql_join, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_intermediate_df = joined_intermediate_df.sort_values(by=[\"master_user_id\", \"created_at\"])\n",
    "joined_data = joined_intermediate_df.groupby(list(processed_loan_df.columns)).tail(1)\n",
    "del(joined_intermediate_df)\n",
    "\n",
    "# Drop xxetra columns which is not required in modelling\n",
    "joined_data.drop([\"master_user_id\", \"disbursed_at\", \"created_at\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b><u><center>Preprocessing</center></u></b></h3>\n",
    "<ul>\n",
    "    <li>Imputation of missing values.</li>\n",
    "    <li>Based on bins computed using weight of evidence in analysis notebook create bands in data.</li>\n",
    "    <li>Creation of dummy variables</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing helper functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_dict = {}\n",
    "\n",
    "def train_missing_value_handler(x):\n",
    "    \"\"\"\n",
    "        input:- train dataframe\n",
    "        output :- dataframe with imputed values based on their mode\n",
    "    \"\"\"\n",
    "    global mode_dict\n",
    "    for column in x.columns:\n",
    "        mode_dict[column] = x[column].mode()[0]\n",
    "        x[column].fillna(mode_dict[column], inplace=True)\n",
    "    return x\n",
    "\n",
    "def test_missing_value_handler(x):\n",
    "    \"\"\"\n",
    "        input:- test dataframe\n",
    "        output :- dataframe with imputed values based on train dataframe mode\n",
    "    \"\"\"\n",
    "    for column in x.columns:\n",
    "        x[column].fillna(mode_dict[column], inplace=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bins Info variables to be used in creation of bands in train & test data\n",
    "\n",
    "past_default_count_bins = [0.0, 1.0, 2.0, 3.0]\n",
    "past_default_count_band = [str(i) for i in range(1,\n",
    "                                                 len(past_default_count_bins))]\n",
    "\n",
    "period_bins = [3.0, 6.0, 9.0, 24.0]\n",
    "period_band = [str(i) for i in range(1,\n",
    "                                     len(period_bins))]\n",
    "\n",
    "amount_bins = [4500.0, 15000.0, 30000.0, 50000.0, 200000.0]\n",
    "amount_band = [str(i) for i in range(1,\n",
    "                                     len(amount_bins))]\n",
    "\n",
    "stated_income_bins = [0.0, 19000.0, 24500.0, 32500.0, 300000.0]\n",
    "stated_income_band = [str(i) for i in range(1,\n",
    "                                            len(stated_income_bins))]\n",
    "\n",
    "line_amount_bins = [10000.0, 35000.0, 50000.0, 200000.0]\n",
    "line_amount_band = [str(i) for i in range(1,\n",
    "                                          len(line_amount_bins))]\n",
    "\n",
    "total_past_records_bins = [0.0, 1.0, 6.0]\n",
    "total_past_records_band = [str(i) for i in range(1,\n",
    "                                                 len(total_past_records_bins))]\n",
    "\n",
    "cibil_score_bins = [-1.0, 665.0, 705.0, 858.0]\n",
    "cibil_score_band = [str(i) for i in range(1,\n",
    "                                          len(cibil_score_bins))]\n",
    "\n",
    "\n",
    "band_dict = {}\n",
    "band_dict[\"past_default_count\"] = [past_default_count_band,\n",
    "                                   past_default_count_bins]\n",
    "band_dict[\"period\"] = [period_band, period_bins]\n",
    "band_dict[\"amount\"] = [amount_band, amount_bins]\n",
    "band_dict[\"stated_income\"] = [stated_income_band, stated_income_bins]\n",
    "band_dict[\"line_amount\"] = [line_amount_band, line_amount_bins]\n",
    "band_dict[\"total_past_records\"] = [total_past_records_band,\n",
    "                                   total_past_records_bins]\n",
    "band_dict[\"cibil_score\"] = [cibil_score_band, cibil_score_bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_assigner(x):\n",
    "    \"\"\"\n",
    "        Responsible of conversion of bins to there respective band category\n",
    "        input :- dataframe\n",
    "        output:- dataframe with continuos variable converted into categorical features based on there bands label.\n",
    "    \"\"\"\n",
    "    global band_dict\n",
    "    \n",
    "    for col in band_dict.keys():\n",
    "        col_labels = band_dict[col][0]\n",
    "        col_bins = band_dict[col][1]\n",
    "        x[col+\"_band\"] = pd.cut(x[col],\n",
    "                                bins=col_bins,\n",
    "                                labels=col_labels,\n",
    "                                include_lowest=True)\n",
    "        x.drop(col, axis=1, inplace=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = []\n",
    "\n",
    "def dummy_creator(df, columns=[], data_type=\"train\"):\n",
    "    \"\"\"\n",
    "        Creation of dummy columns based on their categorical values\n",
    "        input :-\n",
    "            df :- dataframe for which dummy variables has to be created\n",
    "            columns :- list of columns for which dummy creation is required\n",
    "                default = []\n",
    "            data_type :- {\"train\", \"test\"}\n",
    "                info = based on train/test it makes sure that the training & test data has same set of columns\n",
    "                default = \"train\"\n",
    "        output :- \n",
    "            returns DataFrame with dummy columns created\n",
    "    \"\"\"\n",
    "    \n",
    "    global train_columns\n",
    "    \n",
    "    if len(columns) == 0:\n",
    "        df_dummy = pd.get_dummies(df,\n",
    "                                  columns=df.columns,\n",
    "                                 )\n",
    "    else:\n",
    "        df_dummy = pd.get_dummies(df,\n",
    "                                  columns=columns,\n",
    "                                 )\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        train_columns = df_dummy.columns\n",
    "    else:\n",
    "        for column in train_columns:\n",
    "            if column not in df_dummy.columns:\n",
    "                df_dummy[column] = 0\n",
    "    \n",
    "    return df_dummy[train_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train Test Split</h3>\n",
    "Split data into train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(joined_data.target == \"No Default\", 0, 1)\n",
    "X = joined_data.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes NA values from Train & Test\n",
    "X_train_na_removed = train_missing_value_handler(X_train.copy())\n",
    "X_test_na_removed = test_missing_value_handler(X_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of continuos variables into categorical variables using band transformation\n",
    "X_train_grouped = band_assigner(X_train_na_removed.copy())\n",
    "X_test_grouped = band_assigner(X_test_na_removed.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of dummy variables in train & test fro categorical columns\n",
    "X_train_dummy = dummy_creator(X_train_grouped, data_type=\"train\")\n",
    "X_test_dummy = dummy_creator(X_test_grouped, data_type=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><u><center>Modelling</u></b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Selection with parameter tunning</h3>\n",
    "Models tried :-\n",
    "<ul>\n",
    "    <li>Logistic Regression</li>\n",
    "    <li>Random Forest Classifier</li>\n",
    "    <li>KNeighbour Classifier</li>\n",
    "    <li>XGB Classifier</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom Scoring Function for f1_score\n",
    "\"\"\"\n",
    "my_scorer = make_scorer(f1_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter space for Logistic Regression\n",
    "\n",
    "C = np.logspace(0, 4, 3)\n",
    "penalty = ['l2']\n",
    "class_weight = [{0: 0.71, 1: 1.68}, {0: 1, 1: 3}]\n",
    "max_iter = np.arange(900, 1000, 100)\n",
    "\n",
    "hyperparameters = dict(C=C,\n",
    "                       penalty=penalty,\n",
    "                       max_iter=max_iter,\n",
    "                       class_weight=class_weight,\n",
    "                       random_state=[random_seed]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "logistic_search_cv = GridSearchCV(model,\n",
    "                                  hyperparameters,\n",
    "                                  cv=5,\n",
    "                                  scoring=my_scorer,\n",
    "                                  verbose=0)\n",
    "best_logistic_model = logistic_search_cv.fit(X_train_dummy, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of Logistic regression :-  0.45348814463525383\n",
      "Best params :-  {'C': 1.0, 'class_weight': {0: 1, 1: 3}, 'max_iter': 900, 'penalty': 'l2', 'random_state': 21}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score of Logistic regression :- \", logistic_search_cv.best_score_)\n",
    "print(\"Best params :- \", logistic_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 200, 300, 400]\n",
    "class_weight = [{0: 0.71, 1: 1.68}, {0: 1, 1: 3}]\n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "hyperparameters = {\"n_estimators\": n_estimators,\n",
    "                   \"criterion\": [\"entropy\"],\n",
    "                   \"class_weight\": class_weight,\n",
    "                   \"max_features\":max_features,\n",
    "                   \"random_state\":[random_seed]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "rf_search_cv = GridSearchCV(model,\n",
    "                            hyperparameters,\n",
    "                            cv=5,\n",
    "                            scoring=my_scorer,\n",
    "                            verbose=0)\n",
    "best_rf_model = rf_search_cv.fit(X_train_dummy, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of Random Forest classifier :-  0.47096479961522614\n",
      "Best params :-  {'class_weight': {0: 1, 1: 3}, 'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 400, 'random_state': 21}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score of Random Forest classifier :- \", rf_search_cv.best_score_)\n",
    "print(\"Best params :- \", rf_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>KNeighbour Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [4, 5, 6, 7, 8, 9, 10]\n",
    "hyperparameters = {\"n_neighbors\": n_neighbors,\n",
    "                   \"weights\": [\"uniform\", \"distance\"]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "knn_search_cv = GridSearchCV(model,\n",
    "                            hyperparameters,\n",
    "                            cv=5,\n",
    "                            scoring=my_scorer,\n",
    "                            verbose=0)\n",
    "best_knn_model = knn_search_cv.fit(X_train_dummy, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of KNN :-  0.3385746169750867\n",
      "Best params :-  {'n_neighbors': 5, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score of KNN :- \", knn_search_cv.best_score_)\n",
    "print(\"Best params :- \", knn_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [5, 6, 7]\n",
    "min_child_weight = [4, 5, 6]\n",
    "n_estimators = [300, 400, 500]\n",
    "\n",
    "hyperparameters = {\"n_estimators\": n_estimators,\n",
    "                   \"max_depth\": max_depth,\n",
    "                   \"min_child_weight\": min_child_weight,\n",
    "                   \"random_state\":[random_seed]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "xgb_search_cv = GridSearchCV(model,\n",
    "                            hyperparameters,\n",
    "                            cv=5,\n",
    "                            scoring=my_scorer,\n",
    "                            verbose=0)\n",
    "best_xgb_model = xgb_search_cv.fit(X_train_dummy, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of XGB Classifier :-  0.28642346379354783\n",
      "Best params :-  {'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 500, 'random_state': 21}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score of XGB Classifier :- \", xgb_search_cv.best_score_)\n",
    "print(\"Best params :- \", xgb_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><u><center> Final Model </center></u></b></h2>\n",
    "Based on all models score RandomForestClassifier is performing well. So we will use it as Final Model for Classification Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 3}, criterion='entropy',\n",
       "                       max_features='log2', n_estimators=400, random_state=21)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model.fit(X_train_dummy, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model f1_score :-  0.4495867768595041\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_rf_model.predict(X_test_dummy)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Model f1_score :- \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(best_rf_model, X_test_dummy, y_test)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
